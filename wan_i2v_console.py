import os
import torch
import numpy as np
from datetime import datetime
from diffusers import WanImageToVideoPipeline
from diffusers.utils import export_to_video, load_image

# === Hugging Face ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š ===
os.environ["HF_HOME"] = "/workspace/hf_cache"
os.environ["HF_HUB_CACHE"] = "/workspace/hf_cache"

# === å®šæ•° ===
MODEL_ID = "Wan-AI/Wan2.2-TI2V-5B-Diffusers"
DEVICE = "cuda"
DTYPE = torch.bfloat16

# === èªè¨¼ ===
from huggingface_hub import login
login(token=os.environ.get("HF_TOKEN", ""))

# === ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ ===
print("ğŸš€ Loading Wan2.2 pipeline... (this may take a while)")
pipe = WanImageToVideoPipeline.from_pretrained(MODEL_ID, torch_dtype=DTYPE)
pipe.to(DEVICE)
print("âœ… Model loaded successfully.")

# === LoRAé–¢é€£ (å°†æ¥å¯¾å¿œç”¨) ===
"""
lora_uncensored = "/workspace/DiffuserFlux/lora_flux_uncensored.safetensors"
lora_nsfw = "/workspace/DiffuserFlux/lora_flux_nsfw.safetensors"
if os.path.exists(lora_uncensored) and os.path.exists(lora_nsfw):
    pipe.load_lora_weights(lora_uncensored, adapter_name="uncensored")
    pipe.load_lora_weights(lora_nsfw, adapter_name="nsfw")
    pipe.set_adapters(["uncensored", "nsfw"], adapter_weights=[0.8, 0.8])
    print("âœ… LoRA loaded successfully.")
else:
    print("âš ï¸  LoRA files missing. Skipping.")
"""

# === ç”»åƒã®åˆæœŸè¨­å®š ===
current_image = None

print("""
ğŸ§   Wan2.2 Interactive Console
---------------------------------------
Commands:
  load: <filename>   â†’ å…¥åŠ›ç”»åƒã‚’åˆ‡ã‚Šæ›¿ãˆ
  exit               â†’ çµ‚äº†
  (ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›)     â†’ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦ç”Ÿæˆå®Ÿè¡Œ
---------------------------------------
""")

while True:
    prompt = input("\nType prompt (or command): ").strip()

    if prompt.lower() == "exit":
        print("ğŸ‘‹ Bye!")
        break

    elif prompt.lower().startswith("load:"):
        path = prompt.split("load:", 1)[1].strip()
        if os.path.exists(path):
            current_image = load_image(path)
            print(f"ğŸ“· Loaded image: {path}")
        else:
            print(f"âš ï¸  File not found: {path}")
        continue

    if current_image is None:
        print("âš ï¸  No image loaded. Use 'load: <path>' first.")
        continue

    try:
        num_frames_input = input("Number of frames [default=81]: ").strip()
        num_frames = int(num_frames_input) if num_frames_input else 81
    except ValueError:
        num_frames = 81

    # === è§£åƒåº¦è‡ªå‹•èª¿æ•´ ===
    max_area = 480 * 832
    aspect_ratio = current_image.height / current_image.width
    mod_value = pipe.vae_scale_factor_spatial * pipe.transformer.config.patch_size[1]
    height = round(np.sqrt(max_area * aspect_ratio)) // mod_value * mod_value
    width = round(np.sqrt(max_area / aspect_ratio)) // mod_value * mod_value
    resized = current_image.resize((width, height))

    # === ç”Ÿæˆ ===
    print(f"ğŸ¬ Generating video... ({num_frames} frames)")
    generator = torch.Generator(device=DEVICE).manual_seed(0)

    output_frames = pipe(
        image=resized,
        prompt=prompt,
        negative_prompt="è‰²è°ƒè‰³ä¸½,è¿‡æ›,é™æ€,ç»†èŠ‚æ¨¡ç³Šä¸æ¸…,å­—å¹•,é£æ ¼,ä½œå“,ç”»ä½œ,ç”»é¢,é™æ­¢,æ•´ä½“å‘ç°,æœ€å·®è´¨é‡,ä½è´¨é‡,JPEGå‹ç¼©æ®‹ç•™,ä¸‘é™‹çš„,æ®‹ç¼ºçš„,å¤šä½™çš„æ‰‹æŒ‡,ç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨,ç”»å¾—ä¸å¥½çš„è„¸éƒ¨,ç•¸å½¢çš„,æ¯å®¹çš„,å½¢æ€ç•¸å½¢çš„è‚¢ä½“,æ‰‹æŒ‡èåˆ,é™æ­¢ä¸åŠ¨çš„ç”»é¢,æ‚ä¹±çš„èƒŒæ™¯,ä¸‰æ¡è…¿,èƒŒæ™¯äººå¾ˆå¤š,å€’ç€èµ°",
        height=height,
        width=width,
        num_frames=num_frames,
        guidance_scale=3.5,
        num_inference_steps=40,
        generator=generator,
    ).frames[0]

    # === ä¿å­˜ ===
    output_dir = "./tmp"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"wan_output_{timestamp}.mp4"
    save_path = os.path.join(output_dir, filename)

    export_to_video(output_frames, save_path, fps=16)
    print(f"âœ… Completed: {save_path}")
